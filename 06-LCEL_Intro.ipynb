{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "834e3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88109f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002B3047F2650>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002B304738CD0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chatModel = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "chatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027ed56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Introduction to GANs in Computer Vision**\n",
      "=============================================\n",
      "\n",
      "Generative Adversarial Networks (GANs) are a type of deep learning model that has revolutionized the field of computer vision. GANs are designed to generate new, synthetic data that is similar to the training data. In computer vision, GANs can be used for a variety of tasks such as image synthesis, image-to-image translation, and data augmentation.\n",
      "\n",
      "**How GANs Work**\n",
      "----------------\n",
      "\n",
      "A GAN consists of two neural networks: a **Generator** and a **Discriminator**.\n",
      "\n",
      "*   **Generator**: The generator network takes a random noise vector as input and generates a synthetic image.\n",
      "*   **Discriminator**: The discriminator network takes an image (either real or synthetic) as input and outputs a probability that the image is real.\n",
      "\n",
      "The generator and discriminator are trained simultaneously in a competitive manner. The generator tries to generate images that are indistinguishable from real images, while the discriminator tries to correctly classify images as real or synthetic.\n",
      "\n",
      "**Training Process**\n",
      "--------------------\n",
      "\n",
      "The training process of a GAN involves the following steps:\n",
      "\n",
      "1.  **Sample a random noise vector**: Sample a random noise vector from a normal distribution.\n",
      "2.  **Generate a synthetic image**: Pass the noise vector through the generator network to generate a synthetic image.\n",
      "3.  **Sample a real image**: Sample a real image from the training dataset.\n",
      "4.  **Train the discriminator**: Train the discriminator network using the real and synthetic images. The discriminator outputs a probability that the image is real.\n",
      "5.  **Train the generator**: Train the generator network using the output of the discriminator. The generator tries to minimize the loss function, which is typically a binary cross-entropy loss.\n",
      "\n",
      "**Types of GANs in Computer Vision**\n",
      "--------------------------------------\n",
      "\n",
      "Some common types of GANs used in computer vision are:\n",
      "\n",
      "*   **Deep Convolutional GANs (DCGANs)**: DCGANs use convolutional neural networks as the generator and discriminator.\n",
      "*   **Conditional GANs (CGANs)**: CGANs use a conditional distribution to generate images based on a given condition (e.g., class label).\n",
      "*   **Pix2Pix GANs**: Pix2Pix GANs use a conditional GAN to perform image-to-image translation tasks (e.g., converting daytime images to nighttime images).\n",
      "*   **CycleGANs**: CycleGANs use a cycle-consistency loss to perform unpaired image-to-image translation tasks.\n",
      "\n",
      "**Applications of GANs in Computer Vision**\n",
      "--------------------------------------------\n",
      "\n",
      "GANs have numerous applications in computer vision, including:\n",
      "\n",
      "*   **Image synthesis**: GANs can be used to generate realistic images of objects, scenes, and people.\n",
      "*   **Image-to-image translation**: GANs can be used to translate images from one domain to another (e.g., converting daytime images to nighttime images).\n",
      "*   **Data augmentation**: GANs can be used to generate new training data to augment existing datasets.\n",
      "*   **Image editing**: GANs can be used to perform image editing tasks such as removing objects, changing facial expressions, and generating new views of a scene.\n",
      "\n",
      "**Code Example**\n",
      "---------------\n",
      "\n",
      "Here is a simple example of a GAN implemented in PyTorch:\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "from torch.utils.data import Dataset, DataLoader\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# Define the generator network\n",
      "class Generator(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Generator, self).__init__()\n",
      "        self.fc1 = nn.Linear(100, 128)\n",
      "        self.fc2 = nn.Linear(128, 784)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = torch.relu(self.fc1(x))\n",
      "        x = torch.sigmoid(self.fc2(x))\n",
      "        return x\n",
      "\n",
      "# Define the discriminator network\n",
      "class Discriminator(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Discriminator, self).__init__()\n",
      "        self.fc1 = nn.Linear(784, 128)\n",
      "        self.fc2 = nn.Linear(128, 1)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = torch.relu(self.fc1(x))\n",
      "        x = torch.sigmoid(self.fc2(x))\n",
      "        return x\n",
      "\n",
      "# Define the dataset and data loader\n",
      "class MNISTDataset(Dataset):\n",
      "    def __init__(self, images, labels):\n",
      "        self.images = images\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.images)\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        image = self.images[index]\n",
      "        label = self.labels[index]\n",
      "        return image, label\n",
      "\n",
      "# Load the MNIST dataset\n",
      "transform = transforms.Compose([transforms.ToTensor()])\n",
      "train_dataset = MNISTDataset(images=..., labels=...)\n",
      "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
      "\n",
      "# Initialize the generator and discriminator\n",
      "generator = Generator()\n",
      "discriminator = Discriminator()\n",
      "\n",
      "# Define the loss function and optimizer\n",
      "criterion = nn.BCELoss()\n",
      "optimizer_g = optim.Adam(generator.parameters(), lr=0.001)\n",
      "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.001)\n",
      "\n",
      "# Train the GAN\n",
      "for epoch in range(100):\n",
      "    for i, (images, labels) in enumerate(train_loader):\n",
      "        # Sample a random noise vector\n",
      "        noise = torch.randn(32, 100)\n",
      "\n",
      "        # Generate a synthetic image\n",
      "        synthetic_image = generator(noise)\n",
      "\n",
      "        # Train the discriminator\n",
      "        optimizer_d.zero_grad()\n",
      "        real_output = discriminator(images)\n",
      "        synthetic_output = discriminator(synthetic_image.detach())\n",
      "        loss_d = criterion(real_output, torch.ones_like(real_output)) + criterion(synthetic_output, torch.zeros_like(synthetic_output))\n",
      "        loss_d.backward()\n",
      "        optimizer_d.step()\n",
      "\n",
      "        # Train the generator\n",
      "        optimizer_g.zero_grad()\n",
      "        synthetic_output = discriminator(synthetic_image)\n",
      "        loss_g = criterion(synthetic_output, torch.ones_like(synthetic_output))\n",
      "        loss_g.backward()\n",
      "        optimizer_g.step()\n",
      "```\n",
      "Note that this is a simplified example and in practice, you may need to modify the architecture of the generator and discriminator, as well as the loss function and optimizer, to achieve good results.\n"
     ]
    }
   ],
   "source": [
    "respose = chatModel.invoke(\"Expalin me GANs in Computer Vision ?\")\n",
    "\n",
    "print(respose.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177e8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a curious fact about {politician}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d373f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | chatModel | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2235bce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about JFK is that he was a best-selling author before he became the President of the United States. In 1940, at the age of 23, John F. Kennedy wrote a book called \"Why England Slept,\" which was an analysis of the lead-up to World War II and the reasons behind the United Kingdom\\'s slow response to the threat of Nazi Germany. The book became a surprise best-seller, and it helped establish Kennedy as a respected thinker and writer. He later won the Pulitzer Prize in 1957 for his book \"Profiles in Courage,\" which told the stories of eight U.S. senators who took unpopular stands on important issues.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"politician\": \"JFK\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96376f",
   "metadata": {},
   "source": [
    "#### Lagecy Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec86df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf6fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_9476\\2984876514.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  traditional_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "traditional_chain = LLMChain(\n",
    "    llm=chatModel,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "287cb8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s a curious fact about Maradona: \\n\\nMaradona\\'s iconic \"Hand of God\" goal in the 1986 World Cup against England was not just a one-time incident. In a 1997 interview, Maradona revealed that he had previously used his hand to score a goal in a 1981 match for Boca Juniors against Argentinos Juniors, five years before the infamous World Cup incident. However, the earlier incident went largely unnoticed, and it wasn\\'t until the World Cup that the \"Hand of God\" became an infamous part of football history.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traditional_chain.predict(soccer_player=\"Maradona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375062d",
   "metadata": {},
   "source": [
    "#### LangChain expression Language (LCEL) Syntax ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e3bcda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about Diego Maradona is that he was a huge fan of Fidel Castro and the Cuban Revolution. In fact, he got a tattoo of Che Guevara on his right shoulder and was even a close friend of Fidel Castro. Maradona would often visit Cuba and was known to have a deep admiration for the country\\'s socialist ideology. He even named his son Diego Jr.\\'s middle name \"Fidel\" in honor of the Cuban leader. This aspect of Maradona\\'s life is a fascinating example of how his interests and passions extended far beyond the soccer field.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chatModel | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Maradona\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9e906",
   "metadata": {},
   "source": [
    "#### Another Example With LCEL ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9292c5",
   "metadata": {},
   "source": [
    "Usual Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47af8c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imagine you have a team of experts, each specializing in a specific area. When a problem comes up, you don\\'t ask one expert to solve the whole thing. Instead, you ask each expert to focus on the part they\\'re best at, and then you combine their answers to get the final solution.\\n\\nIn AI, a Mixture of Experts (MoE) is similar. It\\'s a type of neural network that uses multiple smaller models, called \"experts,\" to solve a problem. Each expert is trained to be really good at a specific part of the problem, and then the network combines their outputs to get the final answer.\\n\\nHere\\'s a simplified overview of how it works:\\n\\n1. **Multiple Experts**: You have a set of smaller models, each trained on a specific subset of the data. These models are the \"experts.\"\\n2. **Gating Network**: There\\'s a separate network, called the \"gating network,\" that decides which expert to use for each input. It\\'s like a manager who assigns tasks to the experts.\\n3. **Weighted Outputs**: Each expert produces an output, and the gating network assigns a weight to each output. The weights determine how much each expert\\'s output contributes to the final answer.\\n4. **Final Output**: The weighted outputs from all the experts are combined to produce the final output.\\n\\nThe MoE approach has several benefits:\\n\\n* **Improved accuracy**: By using multiple experts, the network can handle complex problems that might be difficult for a single model to solve.\\n* **Efficient use of resources**: Each expert only needs to be trained on a subset of the data, which can reduce the overall computational requirements.\\n* **Flexibility**: The MoE framework can be used for a wide range of tasks, from classification and regression to natural language processing and computer vision.\\n\\nTo illustrate this concept, imagine you\\'re building a chatbot that needs to answer questions on multiple topics, such as music, movies, and sports. You could train a single large model to answer all questions, but that might be inefficient and prone to errors. Instead, you could use a MoE approach with separate experts for each topic, and a gating network that determines which expert to use based on the input question. This way, each expert can focus on its specific area of expertise, and the chatbot can provide more accurate and informative responses.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Explain me in simple terms what is that {technique} in ai\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | chatModel | output_parser\n",
    "\n",
    "chain.invoke({\"technique\": \"Mixture Of Experts\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a8790",
   "metadata": {},
   "source": [
    "Streamed Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0796f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Mixture of Recursion in AI: Simplified Explanation**\n",
      "\n",
      "In Artificial Intelligence (AI), a **Mixture of Recursion** is a technique used to solve complex problems by breaking them down into smaller, more manageable pieces. Here's a simple analogy to help you understand:\n",
      "\n",
      "**Imagine a Matryoshka Doll**\n",
      "\n",
      "Think of a problem as a large Matryoshka doll. Inside this doll, there's a smaller doll, and inside that smaller doll, there's an even smaller one, and so on. Each doll represents a smaller, more manageable piece of the problem.\n",
      "\n",
      "**How Mixture of Recursion Works**\n",
      "\n",
      "In a Mixture of Recursion, the AI algorithm:\n",
      "\n",
      "1. **Breaks down the problem** into smaller sub-problems (like opening the first Matryoshka doll).\n",
      "2. **Solves each sub-problem** using a combination of techniques (like recursion, machine learning, or optimization algorithms).\n",
      "3. **Combines the solutions** to form a solution to the original problem (like putting the dolls back together).\n",
      "\n",
      "The \"mixture\" part refers to the combination of different techniques used to solve each sub-problem. The \"recursion\" part refers to the fact that the algorithm breaks down the problem into smaller pieces, which may involve repeating the same process multiple times (like opening multiple Matryoshka dolls).\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose you want to recognize objects in an image. A Mixture of Recursion algorithm might:\n",
      "\n",
      "1. Break down the image into smaller regions (like individual objects).\n",
      "2. Use a machine learning model to recognize objects in each region.\n",
      "3. Use recursion to further break down complex objects into smaller parts (like recognizing individual features of a face).\n",
      "4. Combine the results to form a final recognition output.\n",
      "\n",
      "By using a Mixture of Recursion, AI algorithms can tackle complex problems more efficiently and effectively, often leading to better performance and accuracy."
     ]
    }
   ],
   "source": [
    "for st in chain.stream({\"technique\": \"Mixture Of Recursion\"}):\n",
    "    print(st, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7a8b8",
   "metadata": {},
   "source": [
    "Batched Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ba3200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**What is Prompt Engineering?**\\n\\nPrompt Engineering is a process in Artificial Intelligence (AI) where you design and optimize the input or \"prompt\" that you give to an AI model to get a specific and desired output.\\n\\n**Think of it like this:**\\n\\nImagine you\\'re asking a friend for help with something. If you ask them a vague question, they might not understand what you want, and their answer might not be helpful. But if you ask them a clear and specific question, they\\'re more likely to give you a helpful and accurate answer.\\n\\n**Prompt Engineering does the same thing for AI models:**\\n\\nIt helps you craft the perfect input or \"prompt\" that tells the AI model exactly what you want it to do or answer. This way, the AI model can give you the most accurate and helpful output possible.\\n\\n**Why is Prompt Engineering important?**\\n\\n1. **Improves AI performance**: By giving the AI model a clear and specific prompt, you can get more accurate and relevant results.\\n2. **Reduces errors**: A well-designed prompt can help avoid misunderstandings and errors in the AI\\'s output.\\n3. **Enhances user experience**: By getting the most out of the AI model, you can create better user experiences and more effective applications.\\n\\n**How is Prompt Engineering done?**\\n\\nPrompt Engineering involves a combination of:\\n\\n1. **Understanding the AI model**: Knowing how the AI model works and what it\\'s capable of.\\n2. **Defining the task**: Clearly defining what you want the AI model to do or answer.\\n3. **Crafting the prompt**: Designing the input or prompt that will elicit the desired output from the AI model.\\n4. **Testing and refining**: Testing the prompt and refining it to get the best possible results.\\n\\nI hope this explanation helped you understand Prompt Engineering in simple terms!',\n",
       " \"Context Engineering in AI is a concept that helps computers understand the situation or environment in which a task is being performed. Here's a simple explanation:\\n\\n**What is Context?**\\nContext refers to the surrounding circumstances, conditions, or environment that influence the meaning of a situation, conversation, or task.\\n\\n**What is Context Engineering?**\\nContext Engineering is the process of designing and building systems that can understand, interpret, and use context to improve the performance of AI models. It involves creating algorithms and techniques that help computers recognize and adapt to different contexts, such as:\\n\\n* Location (e.g., home, office, outdoors)\\n* Time (e.g., morning, evening, daytime)\\n* User preferences (e.g., language, interests)\\n* Task-specific information (e.g., keywords, topics)\\n\\n**How does it work?**\\nContext Engineering involves several steps:\\n\\n1. **Context identification**: Identifying the relevant context for a specific task or situation.\\n2. **Context modeling**: Creating a representation of the context using data, such as user behavior, location, or time.\\n3. **Context integration**: Integrating the context model into the AI system to inform decision-making.\\n4. **Context adaptation**: Adapting the AI system's behavior based on changes in the context.\\n\\n**Benefits**\\nContext Engineering can improve AI systems in many ways, such as:\\n\\n* **Improved accuracy**: By considering the context, AI models can make more informed decisions.\\n* **Personalization**: Context-aware systems can tailor their responses to individual users' needs and preferences.\\n* **Efficiency**: Context Engineering can help AI systems focus on the most relevant information and ignore irrelevant data.\\n\\n**Examples**\\nContext Engineering is used in various applications, such as:\\n\\n* Virtual assistants (e.g., Siri, Alexa) that use context to understand voice commands.\\n* Recommendation systems (e.g., Netflix, Amazon) that consider user behavior and preferences.\\n* Autonomous vehicles that use context to navigate and make decisions.\\n\\nIn summary, Context Engineering is a crucial aspect of AI that enables computers to understand and adapt to different situations, leading to more accurate, personalized, and efficient decision-making.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"technique\": \"Prompt Engineering\"}, {\"technique\": \"Context Engineering\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c141b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
